{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b891750",
   "metadata": {},
   "source": [
    "## 1. Credit card applications\n",
    "<p>Commercial banks receive <em>a lot</em> of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this notebook, we will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_558/img/credit_card.jpg\" alt=\"Credit card being held in hand\"></p>\n",
    "<p>We'll use the <a href=\"http://archive.ics.uci.edu/ml/datasets/credit+approval\">Credit Card Approval dataset</a> from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d13d18",
   "metadata": {},
   "source": [
    "## 2. Import Pandas\n",
    "\n",
    "1. Import pandas and alias it as pd\n",
    "2. Load the dataset cc_approvals.data into a cc_apps dataframe.\n",
    "    - Set the header argument to None.\n",
    "3. Print the first five rows.\n",
    "4. Drop the columns 11 and 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "2a2477ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/cc_approvals.data',names=['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','A15','A16'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['A12','A14'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e269a3c",
   "metadata": {},
   "source": [
    "## 3. Explore the dataset\n",
    "\n",
    "1. Print the basic statistics.\n",
    "2. Print the information of the dataset.\n",
    "3. Print the last 17 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "8c4b265c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>1017.385507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>5210.102598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>395.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A3          A8        A11            A15\n",
       "count  690.000000  690.000000  690.00000     690.000000\n",
       "mean     4.758725    2.223406    2.40000    1017.385507\n",
       "std      4.978163    3.346513    4.86294    5210.102598\n",
       "min      0.000000    0.000000    0.00000       0.000000\n",
       "25%      1.000000    0.165000    0.00000       0.000000\n",
       "50%      2.750000    1.000000    0.00000       5.000000\n",
       "75%      7.207500    2.625000    3.00000     395.500000\n",
       "max     28.000000   28.500000   67.00000  100000.000000"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    object \n",
      " 1   A2      690 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    object \n",
      " 4   A5      690 non-null    object \n",
      " 5   A6      690 non-null    object \n",
      " 6   A7      690 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A13     690 non-null    object \n",
      " 12  A15     690 non-null    int64  \n",
      " 13  A16     690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 75.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6804f9",
   "metadata": {},
   "source": [
    "## 4. Train Test Split\n",
    "\n",
    "Do not split the dataset into X and y, just split the original dataset.\n",
    "\n",
    "random_state=42\n",
    "\n",
    "test_size=0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "4e541590",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('A16',axis=1),df['A16'] , \n",
    "                                   random_state=42,  \n",
    "                                   test_size=0.33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PandasArray>\n",
       "[ 'A1',  'A2',  'A3',  'A4',  'A5',  'A6',  'A7',  'A8',  'A9', 'A10', 'A11',\n",
       " 'A13', 'A15', 'A16']\n",
       "Length: 14, dtype: object"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\n",
      "A1\n",
      "b    314\n",
      "a    140\n",
      "?      8\n",
      "Name: count, dtype: int64\n",
      "A2\n",
      "A2\n",
      "23.58    6\n",
      "23.00    5\n",
      "18.83    5\n",
      "25.00    5\n",
      "?        5\n",
      "        ..\n",
      "56.83    1\n",
      "37.33    1\n",
      "34.58    1\n",
      "16.92    1\n",
      "18.67    1\n",
      "Name: count, Length: 286, dtype: int64\n",
      "A3\n",
      "A3\n",
      "0.000     15\n",
      "1.500     14\n",
      "3.000     13\n",
      "1.250     13\n",
      "2.500     11\n",
      "          ..\n",
      "10.335     1\n",
      "0.665      1\n",
      "9.585      1\n",
      "11.665     1\n",
      "1.165      1\n",
      "Name: count, Length: 174, dtype: int64\n",
      "A4\n",
      "A4\n",
      "u    341\n",
      "y    114\n",
      "?      6\n",
      "l      1\n",
      "Name: count, dtype: int64\n",
      "A5\n",
      "A5\n",
      "g     341\n",
      "p     114\n",
      "?       6\n",
      "gg      1\n",
      "Name: count, dtype: int64\n",
      "A6\n",
      "A6\n",
      "c     91\n",
      "q     52\n",
      "w     48\n",
      "k     41\n",
      "i     40\n",
      "ff    39\n",
      "aa    34\n",
      "m     25\n",
      "cc    25\n",
      "x     22\n",
      "e     16\n",
      "d     15\n",
      "?      7\n",
      "j      6\n",
      "r      1\n",
      "Name: count, dtype: int64\n",
      "A7\n",
      "A7\n",
      "v     261\n",
      "h      91\n",
      "ff     42\n",
      "bb     41\n",
      "z       7\n",
      "?       7\n",
      "dd      5\n",
      "n       3\n",
      "j       3\n",
      "o       2\n",
      "Name: count, dtype: int64\n",
      "A8\n",
      "A8\n",
      "0.000     55\n",
      "0.250     25\n",
      "0.125     24\n",
      "1.000     20\n",
      "0.040     19\n",
      "          ..\n",
      "6.750      1\n",
      "1.665      1\n",
      "13.875     1\n",
      "5.665      1\n",
      "1.210      1\n",
      "Name: count, Length: 110, dtype: int64\n",
      "A9\n",
      "A9\n",
      "t    238\n",
      "f    224\n",
      "Name: count, dtype: int64\n",
      "A10\n",
      "A10\n",
      "f    260\n",
      "t    202\n",
      "Name: count, dtype: int64\n",
      "A11\n",
      "A11\n",
      "0     260\n",
      "1      49\n",
      "2      33\n",
      "3      17\n",
      "6      16\n",
      "7      13\n",
      "5      13\n",
      "11     11\n",
      "4       8\n",
      "8       8\n",
      "12      7\n",
      "14      7\n",
      "10      5\n",
      "9       4\n",
      "15      3\n",
      "16      2\n",
      "20      2\n",
      "17      2\n",
      "23      1\n",
      "67      1\n",
      "Name: count, dtype: int64\n",
      "A13\n",
      "A13\n",
      "g    421\n",
      "s     34\n",
      "p      7\n",
      "Name: count, dtype: int64\n",
      "A15\n",
      "A15\n",
      "0       184\n",
      "1        19\n",
      "500       8\n",
      "1000      7\n",
      "2         6\n",
      "       ... \n",
      "551       1\n",
      "3376      1\n",
      "9800      1\n",
      "117       1\n",
      "38        1\n",
      "Name: count, Length: 182, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A1     0\n",
       "A2     0\n",
       "A3     0\n",
       "A4     0\n",
       "A5     0\n",
       "A6     0\n",
       "A7     0\n",
       "A8     0\n",
       "A9     0\n",
       "A10    0\n",
       "A11    0\n",
       "A13    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in X_train.columns.array:\n",
    "    print(i)\n",
    "    print(X_train[i].value_counts())\n",
    "    \n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47dc98df",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values\n",
    "\n",
    "Convert any '?' to a NaN value from both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 462 entries, 382 to 102\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      462 non-null    object \n",
      " 1   A2      462 non-null    object \n",
      " 2   A3      462 non-null    float64\n",
      " 3   A4      462 non-null    object \n",
      " 4   A5      462 non-null    object \n",
      " 5   A6      462 non-null    object \n",
      " 6   A7      462 non-null    object \n",
      " 7   A8      462 non-null    float64\n",
      " 8   A9      462 non-null    object \n",
      " 9   A10     462 non-null    object \n",
      " 10  A11     462 non-null    int64  \n",
      " 11  A13     462 non-null    object \n",
      " 12  A15     462 non-null    int64  \n",
      "dtypes: float64(2), int64(2), object(9)\n",
      "memory usage: 50.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "87aa9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in X_train.columns.array:\n",
    "    #X_train[i]=X_train[i].replace('?',np.nan)\n",
    "    #X_test[i]=X_test[i].replace('?',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.replace('?',np.nan)\n",
    "X_test=X_test.replace('?',np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17357e6",
   "metadata": {},
   "source": [
    "## 6. Handling Missing Values\n",
    "\n",
    "Impute the numerical data for both training and testing sets with mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['A2'] = X_train['A2'].astype(float)\n",
    "X_test['A2'] = X_test['A2'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "9ecdbf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2\n",
      "A3\n",
      "A8\n",
      "A11\n",
      "A15\n"
     ]
    }
   ],
   "source": [
    "#X_train.fillna(method=)\n",
    "#for i in X_train.columns.array:\n",
    "    #X_train[i].fillna(X_train[i].mean())\n",
    "    #X_train[i]=X_train[i].replace('?',np.nan)\n",
    "    #X_test[i]=X_test[i].replace('?',np.nan)\n",
    "    \n",
    "\n",
    "numeric_columns = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "for column in numeric_columns:\n",
    "    print(column)\n",
    "    X_train[column].fillna(X_train[column].mean(), inplace=True)\n",
    "    X_test[column].fillna(X_train[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef56745",
   "metadata": {},
   "source": [
    "## 7. Handling Missing Values\n",
    "\n",
    "Impute the categorical data for both training and testing sets with mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "81b2094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\n",
      "A4\n",
      "A5\n",
      "A6\n",
      "A7\n",
      "A9\n",
      "A10\n",
      "A13\n"
     ]
    }
   ],
   "source": [
    "categoric_columns = X_train.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "for column in categoric_columns:\n",
    "    print(column)\n",
    "    X_train[column]=X_train[column].fillna(X_train[column].mode()[0])\n",
    "    X_test[column]=X_test[column].fillna(X_train[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0\n",
       "A2     0\n",
       "A3     0\n",
       "A4     0\n",
       "A5     0\n",
       "A6     0\n",
       "A7     0\n",
       "A8     0\n",
       "A9     0\n",
       "A10    0\n",
       "A11    0\n",
       "A13    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     0\n",
       "A2     0\n",
       "A3     0\n",
       "A4     0\n",
       "A5     0\n",
       "A6     0\n",
       "A7     0\n",
       "A8     0\n",
       "A9     0\n",
       "A10    0\n",
       "A11    0\n",
       "A13    0\n",
       "A15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b'], dtype=object)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['A1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767929aa",
   "metadata": {},
   "source": [
    "## 8. Encoding\n",
    "\n",
    "The columns 0, 3, 4, 5, 6, 8, 9, and 12 are categorical, there are several methods we can use to encode the categorical columns. One of the method called get_dummies().\n",
    "\n",
    "Use get_dummies() function to convert the categorical columns to a numerical columns (for training the machine learning algorithms).\n",
    "\n",
    "Do not forget to convert both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 462 entries, 382 to 102\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      462 non-null    object \n",
      " 1   A2      462 non-null    float64\n",
      " 2   A3      462 non-null    float64\n",
      " 3   A4      462 non-null    object \n",
      " 4   A5      462 non-null    object \n",
      " 5   A6      462 non-null    object \n",
      " 6   A7      462 non-null    object \n",
      " 7   A8      462 non-null    float64\n",
      " 8   A9      462 non-null    object \n",
      " 9   A10     462 non-null    object \n",
      " 10  A11     462 non-null    int64  \n",
      " 11  A13     462 non-null    object \n",
      " 12  A15     462 non-null    int64  \n",
      "dtypes: float64(3), int64(2), object(8)\n",
      "memory usage: 50.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3a1c1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_train and X_test into a single DataFrame\n",
    "combined_df = pd.concat([X_train, X_test])\n",
    "\n",
    "# Perform one-hot encoding on categorical columns\n",
    "combined_encoded = pd.get_dummies(combined_df)\n",
    "\n",
    "# Split back into X_train_encoded and X_test_encoded\n",
    "xtrain = combined_encoded.iloc[:len(X_train)]\n",
    "xtest = combined_encoded.iloc[len(X_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7859a",
   "metadata": {},
   "source": [
    "## 9. Split into features and target\n",
    "\n",
    "X_train and y_train will take 462 rows.\n",
    "X_test and y_test will take 228 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6f8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60df8eb6",
   "metadata": {},
   "source": [
    "## 10. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric columns\n",
    "numeric_columns = xtrain.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Apply Min-Max normalization only to numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "xtrain[numeric_columns] = scaler.fit_transform(xtrain[numeric_columns])\n",
    "xtest[numeric_columns] = scaler.transform(xtest[numeric_columns])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "1adc20cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A2', 'A3', 'A8', 'A11', 'A15', 'A1_a', 'A1_b', 'A4_l', 'A4_u', 'A4_y',\n",
       "       'A5_g', 'A5_gg', 'A5_p', 'A6_aa', 'A6_c', 'A6_cc', 'A6_d', 'A6_e',\n",
       "       'A6_ff', 'A6_i', 'A6_j', 'A6_k', 'A6_m', 'A6_q', 'A6_r', 'A6_w', 'A6_x',\n",
       "       'A7_bb', 'A7_dd', 'A7_ff', 'A7_h', 'A7_j', 'A7_n', 'A7_o', 'A7_v',\n",
       "       'A7_z', 'A9_f', 'A9_t', 'A10_f', 'A10_t', 'A13_g', 'A13_p', 'A13_s'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "#xtrain = scaler.fit_transform(xtrain)\n",
    "\n",
    "#xtrain\n",
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dfc1ee",
   "metadata": {},
   "source": [
    "## 11. Train a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "f00d8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15644233]\n",
      "[[-1.21135274 -0.15102634 -0.76692409 -0.47509164 -0.77956735 -0.0584797\n",
      "   0.05876781 -0.37468044  0.03188745  0.3430811   0.03188745 -0.37468044\n",
      "   0.3430811   0.60385986 -0.00930644 -0.76818866  0.17529195 -0.45222689\n",
      "   0.64192422  0.20098095  0.02732623  0.64460484  0.1257272   0.23180214\n",
      "   0.04128338 -0.24458708 -1.21820361  0.50724799 -0.08160143  0.86324135\n",
      "  -0.55930831  0.1689582  -0.70145378 -0.29696223 -0.269563    0.36972934\n",
      "   1.76496046 -1.76467235  0.55972174 -0.55943363  0.76509441 -1.669683\n",
      "   0.9048767 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(xtrain,y_train)\n",
    "\n",
    "\n",
    "print(logmodel.intercept_)\n",
    "print(logmodel.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fe72d",
   "metadata": {},
   "source": [
    "## 12. Make predictions and evaluate the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "74cc23d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-' '+' '-' '-' '-' '-' '-' '+' '-' '-' '-' '+' '-' '+' '-' '+' '-' '-'\n",
      " '-' '-' '-' '-' '-' '+' '-' '-' '+' '+' '-' '-' '+' '+' '+' '+' '+' '+'\n",
      " '+' '+' '+' '+' '+' '+' '-' '+' '-' '+' '-' '-' '+' '-' '-' '+' '-' '-'\n",
      " '+' '-' '+' '-' '+' '-' '+' '+' '+' '-' '-' '+' '+' '+' '+' '-' '-' '+'\n",
      " '-' '+' '-' '-' '-' '-' '+' '-' '+' '+' '-' '-' '+' '-' '+' '+' '+' '+'\n",
      " '+' '+' '+' '+' '+' '+' '+' '+' '-' '-' '-' '-' '+' '-' '+' '+' '-' '+'\n",
      " '-' '+' '-' '+' '+' '+' '+' '-' '+' '+' '-' '+' '-' '-' '+' '-' '-' '+'\n",
      " '-' '-' '+' '+' '+' '-' '+' '-' '+' '+' '+' '+' '-' '+' '+' '+' '+' '+'\n",
      " '-' '-' '-' '+' '+' '-' '-' '-' '-' '+' '-' '+' '+' '+' '-' '-' '+' '-'\n",
      " '-' '-' '-' '-' '-' '+' '-' '+' '-' '-' '+' '-' '+' '-' '-' '-' '-' '-'\n",
      " '-' '+' '+' '-' '+' '-' '-' '+' '+' '+' '-' '+' '-' '+' '+' '+' '+' '+'\n",
      " '+' '+' '+' '+' '-' '+' '+' '-' '+' '+' '-' '-' '+' '-' '+' '+' '-' '-'\n",
      " '+' '-' '-' '-' '+' '+' '+' '-' '+' '-' '-' '-']\n",
      "The classification report :-\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           +       0.79      0.90      0.84       103\n",
      "           -       0.91      0.80      0.85       125\n",
      "\n",
      "    accuracy                           0.85       228\n",
      "   macro avg       0.85      0.85      0.85       228\n",
      "weighted avg       0.85      0.85      0.85       228\n",
      "\n",
      "The accuracy of the model : 0.8464912280701754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import \\\n",
    "     classification_report, confusion_matrix,\\\n",
    "     accuracy_score, precision_score, recall_score, f1_score,roc_auc_score\n",
    "\n",
    "\n",
    "y_pred = logmodel.predict(xtest)\n",
    "print(y_pred)\n",
    "print(f'The classification report :-\\n{classification_report(y_test, y_pred)}')\n",
    "print(f'The accuracy of the model : {accuracy_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd9a1c",
   "metadata": {},
   "source": [
    "## 13. Repeat the steps 11 and 12 for SVM, DT, and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "065b484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           +       0.84      0.81      0.82       103\n",
      "           -       0.84      0.87      0.86       125\n",
      "\n",
      "    accuracy                           0.84       228\n",
      "   macro avg       0.84      0.84      0.84       228\n",
      "weighted avg       0.84      0.84      0.84       228\n",
      "\n",
      "The confusion matrix :-\n",
      "[[ 83  20]\n",
      " [ 16 109]]\n",
      "The accuracy of the model : 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import xticks\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state = 1912, criterion='entropy')\n",
    "tree.fit(xtrain, y_train)\n",
    "\n",
    "y_pred = tree.predict(xtest)\n",
    "\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "print(f'The confusion matrix :-\\n{confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "print(f'The accuracy of the model : {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           +       0.84      0.81      0.82       103\n",
      "           -       0.84      0.87      0.86       125\n",
      "\n",
      "    accuracy                           0.84       228\n",
      "   macro avg       0.84      0.84      0.84       228\n",
      "weighted avg       0.84      0.84      0.84       228\n",
      "\n",
      "The confusion matrix :-\n",
      "[[ 83  20]\n",
      " [ 16 109]]\n",
      "The accuracy of the model : 0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100,\n",
    "                                criterion = 'entropy',\n",
    "                                max_depth = 6,\n",
    "                                min_samples_leaf = 10,\n",
    "                                min_samples_split = 78,\n",
    "                                bootstrap = True,\n",
    "                                oob_score = True,\n",
    "                                random_state = 1912)\n",
    "\n",
    "forest.fit(xtrain, y_train)\n",
    "\n",
    "prediction = forest.predict(xtest)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "print(f'The confusion matrix :-\\n{confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "print(f'The accuracy of the model : {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8377192982456141\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           +       0.77      0.92      0.84       103\n",
      "           -       0.92      0.77      0.84       125\n",
      "\n",
      "    accuracy                           0.84       228\n",
      "   macro avg       0.84      0.85      0.84       228\n",
      "weighted avg       0.85      0.84      0.84       228\n",
      "\n",
      "The confusion matrix :-\n",
      "[[95  8]\n",
      " [29 96]]\n",
      "The accuracy of the model : 0.8377192982456141\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "model = svm.SVC(kernel='linear',random_state=32)\n",
    "\n",
    "model.fit(xtrain,y_train)\n",
    "\n",
    "y_pred=model.predict(xtest)\n",
    "\n",
    "print(model.score(xtest,y_test))\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "print(f'The confusion matrix :-\\n{confusion_matrix(y_test, y_pred)}')\n",
    "\n",
    "print(f'The accuracy of the model : {accuracy_score(y_test, y_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
